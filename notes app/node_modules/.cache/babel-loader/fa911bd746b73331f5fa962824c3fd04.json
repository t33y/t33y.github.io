{"ast":null,"code":"/**\n * @typedef {import('micromark-util-types').Token} Token\n * @typedef {import('micromark-util-types').Chunk} Chunk\n * @typedef {import('micromark-util-types').Event} Event\n */\nimport { splice } from 'micromark-util-chunked';\n\n/**\n * Tokenize subcontent.\n *\n * @param {Event[]} events\n * @returns {boolean}\n */\nexport function subtokenize(events) {\n  /** @type {Record<string, number>} */\n  var jumps = {};\n  var index = -1;\n  /** @type {Event} */\n\n  var event;\n  /** @type {number|undefined} */\n\n  var lineIndex;\n  /** @type {number} */\n\n  var otherIndex;\n  /** @type {Event} */\n\n  var otherEvent;\n  /** @type {Event[]} */\n\n  var parameters;\n  /** @type {Event[]} */\n\n  var subevents;\n  /** @type {boolean|undefined} */\n\n  var more;\n  while (++index < events.length) {\n    while (index in jumps) {\n      index = jumps[index];\n    }\n    event = events[index]; // Add a hook for the GFM tasklist extension, which needs to know if text\n    // is in the first content of a list item.\n\n    if (index && event[1].type === 'chunkFlow' && events[index - 1][1].type === 'listItemPrefix') {\n      subevents = event[1]._tokenizer.events;\n      otherIndex = 0;\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'lineEndingBlank') {\n        otherIndex += 2;\n      }\n      if (otherIndex < subevents.length && subevents[otherIndex][1].type === 'content') {\n        while (++otherIndex < subevents.length) {\n          if (subevents[otherIndex][1].type === 'content') {\n            break;\n          }\n          if (subevents[otherIndex][1].type === 'chunkText') {\n            subevents[otherIndex][1]._isInFirstContentOfListItem = true;\n            otherIndex++;\n          }\n        }\n      }\n    } // Enter.\n\n    if (event[0] === 'enter') {\n      if (event[1].contentType) {\n        Object.assign(jumps, subcontent(events, index));\n        index = jumps[index];\n        more = true;\n      }\n    } // Exit.\n    else if (event[1]._container) {\n      otherIndex = index;\n      lineIndex = undefined;\n      while (otherIndex--) {\n        otherEvent = events[otherIndex];\n        if (otherEvent[1].type === 'lineEnding' || otherEvent[1].type === 'lineEndingBlank') {\n          if (otherEvent[0] === 'enter') {\n            if (lineIndex) {\n              events[lineIndex][1].type = 'lineEndingBlank';\n            }\n            otherEvent[1].type = 'lineEnding';\n            lineIndex = otherIndex;\n          }\n        } else {\n          break;\n        }\n      }\n      if (lineIndex) {\n        // Fix position.\n        event[1].end = Object.assign({}, events[lineIndex][1].start); // Switch container exit w/ line endings.\n\n        parameters = events.slice(lineIndex, index);\n        parameters.unshift(event);\n        splice(events, lineIndex, index - lineIndex + 1, parameters);\n      }\n    }\n  }\n  return !more;\n}\n/**\n * Tokenize embedded tokens.\n *\n * @param {Event[]} events\n * @param {number} eventIndex\n * @returns {Record<string, number>}\n */\n\nfunction subcontent(events, eventIndex) {\n  var token = events[eventIndex][1];\n  var context = events[eventIndex][2];\n  var startPosition = eventIndex - 1;\n  /** @type {number[]} */\n\n  var startPositions = [];\n  var tokenizer = token._tokenizer || context.parser[token.contentType](token.start);\n  var childEvents = tokenizer.events;\n  /** @type {[number, number][]} */\n\n  var jumps = [];\n  /** @type {Record<string, number>} */\n\n  var gaps = {};\n  /** @type {Chunk[]} */\n\n  var stream;\n  /** @type {Token|undefined} */\n\n  var previous;\n  var index = -1;\n  /** @type {Token|undefined} */\n\n  var current = token;\n  var adjust = 0;\n  var start = 0;\n  var breaks = [start]; // Loop forward through the linked tokens to pass them in order to the\n  // subtokenizer.\n\n  while (current) {\n    // Find the position of the event for this token.\n    while (events[++startPosition][1] !== current) {\n      // Empty.\n    }\n    startPositions.push(startPosition);\n    if (!current._tokenizer) {\n      stream = context.sliceStream(current);\n      if (!current.next) {\n        stream.push(null);\n      }\n      if (previous) {\n        tokenizer.defineSkip(current.start);\n      }\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = true;\n      }\n      tokenizer.write(stream);\n      if (current._isInFirstContentOfListItem) {\n        tokenizer._gfmTasklistFirstContentOfListItem = undefined;\n      }\n    } // Unravel the next token.\n\n    previous = current;\n    current = current.next;\n  } // Now, loop back through all events (and linked tokens), to figure out which\n  // parts belong where.\n\n  current = token;\n  while (++index < childEvents.length) {\n    if (\n    // Find a void token that includes a break.\n    childEvents[index][0] === 'exit' && childEvents[index - 1][0] === 'enter' && childEvents[index][1].type === childEvents[index - 1][1].type && childEvents[index][1].start.line !== childEvents[index][1].end.line) {\n      start = index + 1;\n      breaks.push(start); // Help GC.\n\n      current._tokenizer = undefined;\n      current.previous = undefined;\n      current = current.next;\n    }\n  } // Help GC.\n\n  tokenizer.events = []; // If there’s one more token (which is the cases for lines that end in an\n  // EOF), that’s perfect: the last point we found starts it.\n  // If there isn’t then make sure any remaining content is added to it.\n\n  if (current) {\n    // Help GC.\n    current._tokenizer = undefined;\n    current.previous = undefined;\n  } else {\n    breaks.pop();\n  } // Now splice the events from the subtokenizer into the current events,\n  // moving back to front so that splice indices aren’t affected.\n\n  index = breaks.length;\n  while (index--) {\n    var slice = childEvents.slice(breaks[index], breaks[index + 1]);\n    var _start = startPositions.pop();\n    jumps.unshift([_start, _start + slice.length - 1]);\n    splice(events, _start, 2, slice);\n  }\n  index = -1;\n  while (++index < jumps.length) {\n    gaps[adjust + jumps[index][0]] = adjust + jumps[index][1];\n    adjust += jumps[index][1] - jumps[index][0] - 1;\n  }\n  return gaps;\n}","map":null,"metadata":{},"sourceType":"module"}